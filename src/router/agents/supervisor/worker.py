"""
Supervisor Architecture - Worker Implementations

å…·é«”çš„ Worker å¯¦ç¾ï¼Œé€™äº›æ˜¯ Layer 4 çš„å°ˆå®¶åœ˜éšŠã€‚

Worker é¡å‹ï¼š
1. Researcher: æœç´¢èˆ‡èª¿ç ”å°ˆå®¶
2. DataAnalyst: æ•¸æ“šåˆ†æå°ˆå®¶
3. Writer: å…§å®¹å‰µä½œå°ˆå®¶
4. General: é€šç”¨åŠ©æ‰‹

å‹•æ…‹æ¨¡å‹é¸æ“‡ï¼š
Workers æœƒæ ¹æ“š user_context è‡ªå‹•é¸æ“‡å°æ‡‰çš„ AI æ¨¡å‹ã€‚
"""

from typing import Dict, Any, List, Optional
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.language_models import BaseChatModel

from src.router.agents.supervisor.registry import (
    Worker, 
    WorkerType, 
    BaseWorkerMixin,
)
from src.router.agents.supervisor.state import SupervisorState, create_thinking_step
from src.router.agents.supervisor.llm_factory import create_llm_from_state
from src.server.logging_setup import logger

# ä½¿ç”¨æ–°çš„å…¬å…±æ¨¡çµ„
from src.common.prompts import get_prompt
from src.common.function_calls import get_tools_for_langchain, get_tool_executor

# å·¥å…·å°å…¥
from src.tools import get_tavily_search, is_tavily_configured, get_datetime_tool


class BaseWorker(Worker, BaseWorkerMixin):
    """
    Worker åŸºé¡
    
    æä¾›æ‰€æœ‰ Worker å…±ç”¨çš„åŠŸèƒ½ï¼Œæ¸›å°‘é‡è¤‡ä»£ç¢¼ã€‚
    """
    
    def __init__(
        self,
        name: str,
        description: str,
        priority: int = 0,
        worker_type: WorkerType = WorkerType.LLM_POWERED,
        default_temperature: float = 0.5,
    ):
        super().__init__(
            name=name,
            description=description,
            priority=priority,
            worker_type=worker_type,
        )
        self.default_temperature = default_temperature
    
    def get_llm(self, state: SupervisorState, temperature: Optional[float] = None) -> BaseChatModel:
        """æ ¹æ“šç”¨æˆ¶ä¸Šä¸‹æ–‡ç²å–å°æ‡‰çš„ LLM"""
        temp = temperature if temperature is not None else self.default_temperature
        return create_llm_from_state(state, temperature=temp)
    
    def get_query(self, state: SupervisorState) -> Optional[str]:
        """ç²å–ç”¨æˆ¶æŸ¥è©¢"""
        messages = state.get("messages", [])
        return self.get_original_query(state) or self.get_last_user_query(messages)
    
    def get_task_hint(self, state: SupervisorState) -> str:
        """ç²å–ç•¶å‰ä»»å‹™æè¿°çš„æç¤º"""
        current_step = self.get_current_task_step(state)
        if current_step:
            description = current_step.get("description", "")
            if description:
                return f"ä»»å‹™è¦æ±‚ï¼š{description}\n\n"
        return ""
    
    def log_start(self, emoji: str = "ğŸ”§") -> None:
        """è¨˜éŒ„ä»»å‹™é–‹å§‹æ—¥èªŒ"""
        logger.info(f"{emoji} [{self.name}] é–‹å§‹åŸ·è¡Œä»»å‹™")
        self._execution_count += 1


class ResearcherWorker(BaseWorker):
    """
    ç ”ç©¶å°ˆå®¶ Worker
    
    è² è²¬æœç´¢å’Œæ”¶é›†ä¿¡æ¯ã€‚
    æ”¯æŒï¼šWeb æœç´¢ï¼ˆä½¿ç”¨ Tavily APIï¼‰ã€é–±è®€å’Œæ‘˜è¦ã€è¿½å•æœç´¢
    """
    
    def __init__(self, search_tool=None):
        super().__init__(
            name="Researcher",
            description="æœç´¢å°ˆå®¶ï¼Œæ“…é•·åœ¨äº’è¯ç¶²ä¸ŠæŸ¥æ‰¾å’Œæ”¶é›†ä¿¡æ¯ã€‚å¯ä»¥é€²è¡Œå¤šè¼ªæœç´¢å’Œä¿¡æ¯æ•´åˆï¼Œå›ç­”é—œæ–¼äº‹å¯¦ã€æ•¸æ“šã€æ–°èç­‰å•é¡Œã€‚",
            priority=10,
            default_temperature=0.3,
        )
        self.search_tool = search_tool
        self._tavily_configured = is_tavily_configured()
    
    async def _web_search(self, query: str) -> str:
        """åŸ·è¡Œ Web æœç´¢"""
        # 1. å¦‚æœæœ‰å‚³å…¥çš„æœç´¢å·¥å…·ï¼Œä½¿ç”¨å®ƒ
        if self.search_tool:
            try:
                results = await self.search_tool.ainvoke(query)
                return str(results)
            except Exception as e:
                logger.warning(f"æœç´¢å·¥å…·èª¿ç”¨å¤±æ•—: {e}")
        
        # 2. ä½¿ç”¨ Tavily æœç´¢ï¼ˆå¦‚æœå·²é…ç½®ï¼‰
        if self._tavily_configured:
            try:
                tavily = get_tavily_search()
                return await tavily.ainvoke(query)
            except Exception as e:
                logger.warning(f"Tavily æœç´¢å¤±æ•—: {e}")
        
        # 3. é™ç´šæ–¹æ¡ˆ
        logger.warning(f"ğŸ” [{self.name}] Tavily æœªé…ç½®ï¼Œä½¿ç”¨æ¨¡æ“¬æœç´¢")
        return f"é—œæ–¼ '{query}' çš„æœç´¢çµæœï¼š[Tavily æœªé…ç½®ï¼Œè«‹è¨­ç½® TAVILY_API_KEY ç’°å¢ƒè®Šé‡ä»¥å•Ÿç”¨è¯ç¶²æœç´¢]"
    
    async def execute(self, state: SupervisorState) -> Dict[str, Any]:
        """åŸ·è¡Œç ”ç©¶ä»»å‹™"""
        self.log_start("ğŸ”")
        
        query = self.get_query(state)
        if not query:
            return self._create_response("æ²’æœ‰æ”¶åˆ°éœ€è¦ç ”ç©¶çš„å•é¡Œã€‚", state)
        
        try:
            # åŸ·è¡Œæœç´¢
            search_results = await self._web_search(query)
            
            # ä½¿ç”¨ LLM åˆ†ææœç´¢çµæœ
            system_prompt = get_prompt("workers.researcher.system")
            human_prompt = get_prompt("workers.researcher.human")
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", human_prompt),
            ])
            
            llm = self.get_llm(state)
            chain = prompt | llm
            result = await chain.ainvoke({
                "query": query,
                "task_hint": self.get_task_hint(state),
                "search_results": search_results,
            })
            
            content = result.content if hasattr(result, 'content') else str(result)
            
            return self.create_worker_response(
                worker_name=self.name,
                content=content,
                state=state,
                thinking_step=create_thinking_step(
                    step_type="reasoning",
                    content="å®Œæˆæœç´¢å’Œåˆ†æä»»å‹™",
                    worker=self.name,
                ),
            )
            
        except Exception as e:
            logger.error(f"[{self.name}] åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
            return self.create_error_response(
                worker_name=self.name,
                error_message=f"ç ”ç©¶ä»»å‹™åŸ·è¡Œå¤±æ•—: {str(e)}",
                state=state,
            )


class DataAnalystWorker(BaseWorker):
    """
    æ•¸æ“šåˆ†æå°ˆå®¶ Worker
    
    è² è²¬æ•¸æ“šæŸ¥è©¢å’Œåˆ†æã€‚
    """
    
    def __init__(self):
        super().__init__(
            name="DataAnalyst",
            description="æ•¸æ“šåˆ†æå°ˆå®¶ï¼Œæ“…é•·æŸ¥è©¢æ¥­å‹™æ•¸æ“šåº«ã€åˆ†æéŠ·å”®/åº«å­˜/ç”¨æˆ¶ç­‰æ¥­å‹™æ•¸æ“šè¶¨å‹¢ã€ç”Ÿæˆæ•¸æ“šå ±å‘Šã€‚ã€æ³¨æ„ã€‘ä¸è² è²¬å›ç­”ç•¶å‰æ—¥æœŸã€æ™‚é–“ç­‰ç³»çµ±ä¿¡æ¯å•é¡Œï¼Œé€™é¡å•é¡Œè«‹äº¤çµ¦ Generalã€‚",
            priority=10,
            default_temperature=0.1,
        )
    
    async def execute(self, state: SupervisorState) -> Dict[str, Any]:
        """åŸ·è¡Œæ•¸æ“šåˆ†æä»»å‹™"""
        self.log_start("ğŸ“Š")
        
        query = self.get_query(state)
        if not query:
            return self._create_response("æ²’æœ‰æ”¶åˆ°éœ€è¦åˆ†æçš„æ•¸æ“šå•é¡Œã€‚", state)
        
        try:
            system_prompt = get_prompt("workers.data_analyst.system")
            human_prompt = get_prompt("workers.data_analyst.human")
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", human_prompt),
            ])
            
            llm = self.get_llm(state)
            chain = prompt | llm
            result = await chain.ainvoke({
                "query": query,
                "task_hint": self.get_task_hint(state),
            })
            
            content = result.content if hasattr(result, 'content') else str(result)
            
            return self.create_worker_response(
                worker_name=self.name,
                content=content,
                state=state,
                thinking_step=create_thinking_step(
                    step_type="reasoning",
                    content="å®Œæˆæ•¸æ“šåˆ†æä»»å‹™",
                    worker=self.name,
                ),
            )
            
        except Exception as e:
            logger.error(f"[{self.name}] åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
            return self.create_error_response(
                worker_name=self.name,
                error_message=f"æ•¸æ“šåˆ†æä»»å‹™åŸ·è¡Œå¤±æ•—: {str(e)}",
                state=state,
            )


class WriterWorker(BaseWorker):
    """
    æ–‡æ¡ˆå°ˆå®¶ Worker
    
    è² è²¬æ’°å¯«å’Œç¸½çµï¼Œå¯ä»¥æ•´åˆå…¶ä»– Worker çš„çµæœç”Ÿæˆæœ€çµ‚å ±å‘Šã€‚
    """
    
    def __init__(self):
        super().__init__(
            name="Writer",
            description="æ–‡æ¡ˆå°ˆå®¶ï¼Œæ“…é•·æ’°å¯«å ±å‘Šã€ç¸½çµä¿¡æ¯ã€æ•´ç†æ–‡æª”ã€‚å¯ä»¥æ•´åˆå¤šå€‹ä¾†æºçš„ä¿¡æ¯ï¼Œæ ¹æ“šç”¨æˆ¶èªæ°£åå¥½ç”Ÿæˆçµæ§‹åŒ–çš„æœ€çµ‚è¼¸å‡ºï¼ˆMarkdown/è¡¨æ ¼ï¼‰ã€‚",
            priority=5,
            default_temperature=0.7,
        )
    
    async def execute(self, state: SupervisorState) -> Dict[str, Any]:
        """åŸ·è¡Œæ–‡æ¡ˆæ’°å¯«ä»»å‹™"""
        self.log_start("âœï¸")
        
        messages = state.get("messages", [])
        worker_outputs = self.get_worker_outputs(messages)
        original_query = self.get_original_query(state)
        user_context = self.get_user_context(state)
        language = user_context.get("language", "zh-CN")
        
        if not worker_outputs and not original_query:
            return self._create_response("æ²’æœ‰å¯ç”¨çš„ä¿¡æ¯ä¾†æ’°å¯«å…§å®¹ã€‚", state)
        
        try:
            # æº–å‚™ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = ""
            if worker_outputs:
                context_info = "\n\n".join([
                    f"### {output['name']} çš„è¼¸å‡ºï¼š\n{output['content']}"
                    for output in worker_outputs
                ])
            
            system_prompt = get_prompt("workers.writer.system", language="{language}")
            human_prompt = get_prompt("workers.writer.human")
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", human_prompt),
            ])
            
            llm = self.get_llm(state)
            chain = prompt | llm
            result = await chain.ainvoke({
                "query": original_query or "æ•´åˆç¾æœ‰ä¿¡æ¯",
                "task_hint": self.get_task_hint(state),
                "context": context_info or "ç„¡é¡å¤–ä¿¡æ¯",
                "language": "ä¸­æ–‡" if "zh" in language else "English",
            })
            
            content = result.content if hasattr(result, 'content') else str(result)
            
            return self.create_worker_response(
                worker_name=self.name,
                content=content,
                state=state,
                thinking_step=create_thinking_step(
                    step_type="reasoning",
                    content=f"å®Œæˆæ–‡æ¡ˆæ’°å¯«ä»»å‹™ï¼Œæ•´åˆäº† {len(worker_outputs)} å€‹ä¿¡æ¯æº",
                    worker=self.name,
                ),
            )
            
        except Exception as e:
            logger.error(f"[{self.name}] åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
            return self.create_error_response(
                worker_name=self.name,
                error_message=f"æ–‡æ¡ˆæ’°å¯«ä»»å‹™åŸ·è¡Œå¤±æ•—: {str(e)}",
                state=state,
            )


class GeneralWorker(BaseWorker):
    """
    é€šç”¨ Worker
    
    è™•ç†ä¸€èˆ¬æ€§çš„å°è©±å’Œä»»å‹™ã€‚
    æ”¯æŒ Function Calling ä¾†ç²å–å¯¦æ™‚ä¿¡æ¯ï¼ˆå¦‚ç•¶å‰æ™‚é–“ï¼‰ã€‚
    å¦‚æœæ¨¡å‹ä¸æ”¯æŒ toolsï¼Œæœƒè‡ªå‹•é™ç´šåˆ°ç›´æ¥æ³¨å…¥æ™‚é–“çš„æ–¹å¼ã€‚
    """
    
    # å·¥å…·åŸ·è¡Œå™¨æ˜ å°„
    TOOL_EXECUTORS = {
        "get_current_datetime": lambda params: get_datetime_tool().invoke(params),
    }
    
    def __init__(self):
        super().__init__(
            name="General",
            description="é€šç”¨åŠ©æ‰‹ï¼Œå¯ä»¥è™•ç†å„ç¨®ä¸€èˆ¬æ€§çš„å°è©±å’Œä»»å‹™ã€‚ã€é‡è¦ã€‘è² è²¬å›ç­”é—œæ–¼ç•¶å‰æ—¥æœŸã€æ™‚é–“ã€æ˜ŸæœŸå¹¾ç­‰æ™‚é–“ç›¸é—œå•é¡Œã€‚ä¹Ÿé©åˆè™•ç†ç°¡å–®å•ç­”ã€é–’èŠã€èº«ä»½ä»‹ç´¹ç­‰å ´æ™¯ã€‚",
            priority=1,
            default_temperature=0.5,
        )
        self._tools_supported = True
    
    def _get_tools(self) -> List[Dict[str, Any]]:
        """ç²å– LangChain æ ¼å¼çš„å·¥å…·å®šç¾©"""
        try:
            return get_tools_for_langchain(["get_current_datetime"])
        except Exception as e:
            logger.warning(f"[{self.name}] ç²å–å·¥å…·å®šç¾©å¤±æ•—: {e}")
            return []
    
    def _get_current_datetime_info(self, timezone: str = "Asia/Shanghai") -> str:
        """ç›´æ¥ç²å–ç•¶å‰æ™‚é–“ä¿¡æ¯ï¼ˆé™ç´šæ–¹æ¡ˆï¼‰"""
        tool = get_datetime_tool(timezone)
        response = tool.get_datetime(timezone)
        return f"ä»Šå¤©æ˜¯ {response.date} {response.weekday}ï¼Œç¾åœ¨æ™‚é–“æ˜¯ {response.time}ï¼ˆ{response.timezone}ï¼‰"
    
    async def _execute_tool(self, tool_name: str, tool_args: Dict[str, Any]) -> str:
        """åŸ·è¡Œå·¥å…·èª¿ç”¨"""
        executor = self.TOOL_EXECUTORS.get(tool_name)
        if executor:
            logger.info(f"ğŸ”§ [{self.name}] èª¿ç”¨å·¥å…·: {tool_name}")
            return executor(tool_args)
        return f"æœªçŸ¥å·¥å…·: {tool_name}"
    
    async def _execute_with_tools(
        self, 
        llm: BaseChatModel, 
        prompt: ChatPromptTemplate,
        query: str,
        history_messages: List,
        language: str,
        system_prompt: str,
    ) -> str:
        """ä½¿ç”¨ Function Calling åŸ·è¡Œ"""
        tools = self._get_tools()
        if not tools:
            raise ValueError("No tools available")
        
        llm_with_tools = llm.bind_tools(tools)
        chain = prompt | llm_with_tools
        
        result = await chain.ainvoke({
            "query": query,
            "history": history_messages,
            "language": language,
        })
        
        # è™•ç†å·¥å…·èª¿ç”¨
        if hasattr(result, 'tool_calls') and result.tool_calls:
            logger.info(f"[{self.name}] LLM è«‹æ±‚èª¿ç”¨ {len(result.tool_calls)} å€‹å·¥å…·")
            
            tool_results = []
            for tool_call in result.tool_calls:
                tool_name = tool_call.get("name", "")
                tool_args = tool_call.get("args", {})
                tool_result = await self._execute_tool(tool_name, tool_args)
                tool_results.append({"tool": tool_name, "result": tool_result})
            
            # æ§‹å»ºåŒ…å«å·¥å…·çµæœçš„æ¶ˆæ¯
            from langchain_core.messages import ToolMessage
            
            tool_messages = []
            for i, tool_call in enumerate(result.tool_calls):
                tool_messages.append(ToolMessage(
                    content=tool_results[i]["result"],
                    tool_call_id=tool_call.get("id", f"tool_{i}"),
                ))
            
            # ç¬¬äºŒæ¬¡èª¿ç”¨
            final_prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{query}"),
                result,
                *tool_messages,
            ])
            
            final_chain = final_prompt | llm
            final_result = await final_chain.ainvoke({
                "query": query,
                "history": history_messages,
                "language": language,
            })
            
            return final_result.content if hasattr(final_result, 'content') else str(final_result)
        
        return result.content if hasattr(result, 'content') else str(result)
    
    async def _execute_without_tools(
        self,
        llm: BaseChatModel,
        query: str,
        history_messages: List,
        language: str,
        timezone: str,
    ) -> str:
        """ä¸ä½¿ç”¨ Function Calling åŸ·è¡Œï¼ˆé™ç´šæ–¹æ¡ˆï¼‰"""
        logger.info(f"[{self.name}] ä½¿ç”¨é™ç´šæ–¹æ¡ˆï¼ˆç›´æ¥æ³¨å…¥æ™‚é–“ä¿¡æ¯ï¼‰")
        
        datetime_info = self._get_current_datetime_info(timezone)
        system_prompt = get_prompt(
            "workers.general.system_with_datetime",
            datetime_info=datetime_info,
            language=language,
        )
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{query}"),
        ])
        
        chain = prompt | llm
        result = await chain.ainvoke({
            "query": query,
            "history": history_messages,
            "language": language,
        })
        
        return result.content if hasattr(result, 'content') else str(result)
    
    async def execute(self, state: SupervisorState) -> Dict[str, Any]:
        """åŸ·è¡Œé€šç”¨ä»»å‹™"""
        self.log_start("ğŸ’¬")
        
        query = self.get_query(state)
        user_context = self.get_user_context(state)
        
        if not query:
            default_greeting = get_prompt("workers.general.default_greeting")
            return self._create_response(default_greeting, state)
        
        try:
            language = user_context.get("language", "zh-CN")
            timezone = user_context.get("timezone", "Asia/Shanghai")
            language_text = "ä¸­æ–‡" if "zh" in language else "English"
            
            messages = state.get("messages", [])
            history_messages = [
                msg for msg in messages[:-1]
                if isinstance(msg, (HumanMessage, AIMessage))
            ][-6:]
            
            llm = self.get_llm(state)
            
            # å˜—è©¦ä½¿ç”¨ Function Calling
            if self._tools_supported:
                try:
                    system_prompt = get_prompt("workers.general.system", language="{language}")
                    prompt = ChatPromptTemplate.from_messages([
                        ("system", system_prompt),
                        MessagesPlaceholder(variable_name="history"),
                        ("human", "{query}"),
                    ])
                    
                    content = await self._execute_with_tools(
                        llm=llm,
                        prompt=prompt,
                        query=query,
                        history_messages=history_messages,
                        language=language_text,
                        system_prompt=system_prompt,
                    )
                except Exception as e:
                    error_msg = str(e).lower()
                    if "does not support tools" in error_msg or ("tool" in error_msg and "support" in error_msg):
                        logger.warning(f"[{self.name}] æ¨¡å‹ä¸æ”¯æŒ toolsï¼Œåˆ‡æ›åˆ°é™ç´šæ–¹æ¡ˆ")
                        self._tools_supported = False
                        content = await self._execute_without_tools(
                            llm=llm,
                            query=query,
                            history_messages=history_messages,
                            language=language_text,
                            timezone=timezone,
                        )
                    else:
                        raise
            else:
                content = await self._execute_without_tools(
                    llm=llm,
                    query=query,
                    history_messages=history_messages,
                    language=language_text,
                    timezone=timezone,
                )
            
            return self.create_worker_response(
                worker_name=self.name,
                content=content,
                state=state,
            )
            
        except Exception as e:
            logger.error(f"[{self.name}] åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
            return self.create_error_response(
                worker_name=self.name,
                error_message=f"è™•ç†è«‹æ±‚æ™‚å‡ºç¾å•é¡Œ: {str(e)}",
                state=state,
            )


# Worker é¡æ˜ å°„
WORKER_CLASSES = {
    "Researcher": ResearcherWorker,
    "DataAnalyst": DataAnalystWorker,
    "Writer": WriterWorker,
    "General": GeneralWorker,
}


def register_default_workers() -> None:
    """è¨»å†Šæ‰€æœ‰é»˜èªçš„ Worker"""
    from src.router.agents.supervisor.registry import register_worker, get_registry
    
    registry = get_registry()
    
    if not registry.is_empty():
        logger.info("Workers å·²è¨»å†Šï¼Œè·³éé‡è¤‡è¨»å†Š")
        return
    
    for worker_class in WORKER_CLASSES.values():
        register_worker(worker_class())
    
    logger.info(f"å·²è¨»å†Š {len(WORKER_CLASSES)} å€‹é»˜èª Worker")
