"""
Supervisor Architecture - Supervisor Node

Supervisor èŠ‚ç‚¹è´Ÿè´£ï¼š
1. ä»»åŠ¡è§„åˆ’ï¼šåˆ†æå¤æ‚æŒ‡ä»¤ï¼Œåˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤
2. å†³ç­–è·¯ç”±ï¼šå†³å®šä¸‹ä¸€æ­¥åº”è¯¥ç”±å“ªä¸ª Worker æ‰§è¡Œ
3. è¿›åº¦è¿½è¸ªï¼šç›‘æ§ä»»åŠ¡æ‰§è¡Œè¿›åº¦ï¼Œå†³å®šæ˜¯å¦ç»“æŸ

åŠ¨æ€æ¨¡å‹é€‰æ‹©ï¼š
Supervisor ä¼šæ ¹æ® user_context è‡ªåŠ¨é€‰æ‹©å¯¹åº”çš„ AI æ¨¡å‹ï¼š
- Customize è·¯ç”± â†’ ä½¿ç”¨ SELF_MODEL_* é…ç½®
- Qwen è·¯ç”± â†’ ä½¿ç”¨ QWEN_* é…ç½®
- é¢„è®¾ â†’ æŒ‰é¡ºåºå°è¯•å¯ç”¨çš„æ¨¡å‹
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional, Callable, List
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.language_models import BaseChatModel
from pydantic import BaseModel, Field
from src.router.agents.supervisor.state import (
    SupervisorState, 
    MAX_ITERATIONS,
    MAX_TASK_STEPS,
    TaskStep,
    TaskStatus,
    ThinkingStep,
    create_thinking_step,
    create_task_step,
)
from src.router.agents.supervisor.registry import get_registry
from src.router.agents.supervisor.llm_factory import create_llm_from_state
from src.server.logging_setup import logger
from src.common.prompts import get_prompt


class TaskPlan(BaseModel):
    """
    ä»»åŠ¡è§„åˆ’ç»“æœ
    
    Supervisor åˆ†æç”¨æˆ·è¯·æ±‚åï¼Œç”Ÿæˆçš„ä»»åŠ¡è§„åˆ’ã€‚
    """
    steps: List[Dict[str, str]] = Field(
        default_factory=list,
        description="ä»»åŠ¡æ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å« workerï¼ˆæ‰§è¡Œè€…ï¼‰å’Œ descriptionï¼ˆæè¿°ï¼‰"
    )
    reasoning: str = Field(
        default="",
        description="è§„åˆ’ç†ç”±"
    )


class RouteDecision(BaseModel):
    """
    Supervisor çš„è·¯ç”±å†³ç­–ç»“æœ
    
    ä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿ LLM åªèƒ½è¿”å›é¢„å®šä¹‰çš„è·¯ç”±é€‰é¡¹ã€‚
    """
    next: str = Field(
        ...,
        description="ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„è§’è‰²åç§°ï¼Œå¦‚æœä»»åŠ¡å®Œæˆåˆ™é€‰æ‹© FINISH"
    )
    reasoning: str = Field(
        default="",
        description="å†³ç­–ç†ç”±ï¼ˆç”¨äºè°ƒè¯•å’Œæµå¼è¾“å‡ºï¼‰"
    )
    should_replan: bool = Field(
        default=False,
        description="æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’ä»»åŠ¡ï¼ˆå½“å½“å‰è®¡åˆ’ä¸è¶³ä»¥å®Œæˆä»»åŠ¡æ—¶ï¼‰"
    )


@dataclass
class SupervisorConfig:
    """
    Supervisor é…ç½®ç±»
    
    æ³¨æ„ï¼šæ¨¡å‹é€‰æ‹©å·²æ”¹ä¸ºåŠ¨æ€æ–¹å¼ï¼Œä» user_context ä¸­è¯»å–ã€‚
    è¿™é‡Œåªä¿ç•™ Supervisor è¡Œä¸ºç›¸å…³çš„é…ç½®ã€‚
    """
    temperature: float = 0.0  # Supervisor ä½¿ç”¨ä½æ¸©åº¦ä»¥ç¡®ä¿å†³ç­–ç¨³å®š
    max_iterations: int = MAX_ITERATIONS
    max_task_steps: int = MAX_TASK_STEPS
    enable_planning: bool = True  # æ˜¯å¦å¯ç”¨ä»»åŠ¡è§„åˆ’
    
    def validate(self) -> None:
        """éªŒè¯é…ç½®ï¼ˆæ¨¡å‹é…ç½®å·²ç§»è‡³ llm_factoryï¼‰"""
        pass


# æç¤ºè¯ç°åœ¨ä»é…ç½®æ–‡ä»¶è¯»å–ï¼šsrc/common/prompts/config.yaml
# ä½¿ç”¨ get_prompt("supervisor.planning") å’Œ get_prompt("supervisor.routing") è·å–


def _build_planning_prompt(worker_list: str, max_steps: int) -> ChatPromptTemplate:
    """æ„å»ºä»»åŠ¡è§„åˆ’ Promptï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰"""
    # ä»é…ç½®æ–‡ä»¶è·å–æç¤ºè¯ï¼Œæ”¯æŒæ¨¡æ¿å˜é‡
    system_prompt = get_prompt(
        "supervisor.planning",
        worker_list=worker_list,
        max_steps=max_steps,
    )
    
    # è·å–è§„åˆ’å®Œæˆæç¤ºè¯
    planning_complete = get_prompt(
        "supervisor.planning_complete",
        default='è¯·åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œåˆ¶å®šä¸€ä¸ªæ‰§è¡Œè®¡åˆ’ã€‚è¿”å› JSON æ ¼å¼ï¼š{{"steps": [{{"worker": "ä¸“å®¶åç§°", "description": "ä»»åŠ¡æè¿°"}}], "reasoning": "è§„åˆ’ç†ç”±"}}'
    )
    
    return ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        ("system", planning_complete),
    ])


def _build_routing_prompt(
    worker_list: str, 
    worker_names: list,
    task_plan: str,
    completed_steps: int,
    total_steps: int,
) -> ChatPromptTemplate:
    """æ„å»ºè·¯ç”±å†³ç­– Promptï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰"""
    # ä»é…ç½®æ–‡ä»¶è·å–æç¤ºè¯ï¼Œæ”¯æŒæ¨¡æ¿å˜é‡
    system_prompt = get_prompt(
        "supervisor.routing",
        worker_list=worker_list,
        worker_options=', '.join(worker_names),
        task_plan=task_plan,
        completed_steps=completed_steps,
        total_steps=total_steps,
    )
    
    # è·å–è·¯ç”±å†³ç­–æç¤ºè¯
    routing_decision = get_prompt(
        "supervisor.routing_decision",
        default="æ ¹æ®ä»¥ä¸Šå¯¹è¯å†å²å’Œä»»åŠ¡è¿›åº¦ï¼Œè¯·åšå‡ºä½ çš„å†³ç­–ï¼šä¸‹ä¸€æ­¥äº¤ç»™å“ªä¸ªä¸“å®¶ï¼Ÿæˆ–è€…ä»»åŠ¡æ˜¯å¦å·²ç»å®Œæˆï¼Ÿ"
    )
    
    return ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        ("system", routing_decision),
    ])


def _get_llm_from_state(state: SupervisorState, temperature: float = 0.0) -> BaseChatModel:
    """
    ä»çŠ¶æ€ä¸­è·å– LLM å®ä¾‹
    
    æ ¹æ® user_context åŠ¨æ€é€‰æ‹©å¯¹åº”çš„æ¨¡å‹ã€‚
    Supervisor ä½¿ç”¨è¾ƒä½æ¸©åº¦ä»¥ç¡®ä¿å†³ç­–ç¨³å®šã€‚
    """
    import os
    # æ¸…ç†ä¸ httpx SSL éªŒè¯å†²çªçš„ç¯å¢ƒå˜é‡
    for _var in ("SSL_CERT_FILE", "SSL_KEY_FILE"):
        if _var in os.environ:
            del os.environ[_var]
    
    return create_llm_from_state(state, temperature=temperature)


def _format_task_plan(task_plan: List[TaskStep]) -> str:
    """æ ¼å¼åŒ–ä»»åŠ¡è®¡åˆ’ä¸ºå­—ç¬¦ä¸²"""
    if not task_plan:
        return "æ— ä»»åŠ¡è®¡åˆ’"
    
    lines = []
    for i, step in enumerate(task_plan):
        status_emoji = {
            TaskStatus.PENDING: "â³",
            TaskStatus.IN_PROGRESS: "ğŸ”„",
            TaskStatus.COMPLETED: "âœ…",
            TaskStatus.FAILED: "âŒ",
            TaskStatus.SKIPPED: "â­ï¸",
        }.get(step.get("status", TaskStatus.PENDING), "â³")
        
        lines.append(f"{i+1}. [{status_emoji}] {step.get('worker', 'Unknown')}: {step.get('description', 'No description')}")
    
    return "\n".join(lines)


def create_supervisor_node(
    config: Optional[SupervisorConfig] = None,
    llm: Optional[BaseChatModel] = None,
) -> Callable[[SupervisorState], Dict[str, Any]]:
    """
    åˆ›å»º Supervisor èŠ‚ç‚¹
    
    Supervisor ä½¿ç”¨ LLM æ¥åˆ†æå½“å‰çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥åº”è¯¥ï¼š
    1. åˆ¶å®šä»»åŠ¡è§„åˆ’ï¼ˆå¦‚æœè¿˜æ²¡æœ‰è§„åˆ’ï¼‰
    2. äº¤ç»™å“ªä¸ª Worker å¤„ç†
    3. æˆ–è€…ç»“æŸä»»åŠ¡ï¼ˆFINISHï¼‰
    
    åŠ¨æ€æ¨¡å‹é€‰æ‹©ï¼š
    LLM ä¼šæ ¹æ® state["user_context"] åŠ¨æ€é€‰æ‹©å¯¹åº”çš„æ¨¡å‹ã€‚
    è¿™å…è®¸ä¸åŒè·¯ç”±ï¼ˆCustomizeã€Qwenã€Geminiï¼‰ä½¿ç”¨å„è‡ªé…ç½®çš„æ¨¡å‹ã€‚
    
    Args:
        config: Supervisor é…ç½®ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        llm: å¯é€‰çš„ LLM å®ä¾‹ï¼Œç”¨äºæµ‹è¯•æ—¶æ³¨å…¥ mockï¼ˆè¦†ç›–åŠ¨æ€é€‰æ‹©ï¼‰
    
    Returns:
        ä¸€ä¸ªå¼‚æ­¥å‡½æ•°ï¼Œæ¥å— SupervisorState å¹¶è¿”å›æ›´æ–°åçš„çŠ¶æ€
    """
    if config is None:
        config = SupervisorConfig()
    config.validate()
    
    # å¦‚æœæä¾›äº† llmï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼Œåˆ™ä½¿ç”¨å®ƒï¼›å¦åˆ™ä¼šåœ¨æ¯æ¬¡è¯·æ±‚æ—¶æ ¹æ® state åŠ¨æ€åˆ›å»º
    _fixed_llm = llm
    
    async def _plan_task(state: SupervisorState, registry) -> Dict[str, Any]:
        """
        ä»»åŠ¡è§„åˆ’é˜¶æ®µ
        
        åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œåˆ†è§£ä¸ºå¤šä¸ªæ‰§è¡Œæ­¥éª¤ã€‚
        """
        logger.info("ğŸ“‹ [Supervisor] å¼€å§‹ä»»åŠ¡è§„åˆ’...")
        
        # æ ¹æ®ç”¨æˆ·ä¸Šä¸‹æ–‡åŠ¨æ€è·å– LLM
        llm = _fixed_llm or _get_llm_from_state(state, temperature=config.temperature)
        
        worker_list = registry.get_formatted_descriptions()
        prompt = _build_planning_prompt(worker_list, config.max_task_steps)
        
        try:
            planning_chain = prompt | llm.with_structured_output(TaskPlan)
            result = await planning_chain.ainvoke({"messages": state.get("messages", [])})
            
            if isinstance(result, TaskPlan):
                # è½¬æ¢ä¸º TaskStep åˆ—è¡¨
                task_plan = []
                for i, step in enumerate(result.steps):
                    # æ¸…ç† Worker åç§°ï¼Œç§»é™¤å¯èƒ½çš„ç±»å‹æ ‡è®°ï¼ˆå¦‚ "Researcher [llm_powered]" -> "Researcher"ï¼‰
                    worker_name = step.get("worker", "General")
                    if "[" in worker_name:
                        worker_name = worker_name.split("[")[0].strip()
                    
                    task_step = create_task_step(
                        step_id=f"step_{i+1}",
                        worker=worker_name,
                        description=step.get("description", ""),
                    )
                    task_plan.append(task_step)
                
                # è®°å½•æ€è€ƒæ­¥éª¤
                thinking_step = create_thinking_step(
                    step_type="planning",
                    content=f"ä»»åŠ¡è§„åˆ’å®Œæˆï¼š{result.reasoning}\nè®¡åˆ’æ­¥éª¤ï¼š{len(task_plan)} ä¸ª",
                )
                
                logger.info(f"ğŸ“‹ [Supervisor] ä»»åŠ¡è§„åˆ’å®Œæˆï¼Œå…± {len(task_plan)} ä¸ªæ­¥éª¤")
                
                return {
                    "task_plan": task_plan,
                    "current_step_index": 0,
                    "original_query": state.get("messages", [{}])[0].content if state.get("messages") else "",
                    "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
                }
            
        except Exception as e:
            logger.warning(f"ä»»åŠ¡è§„åˆ’å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å•æ­¥è®¡åˆ’: {e}")
        
        # é™çº§ï¼šåˆ›å»ºå•æ­¥è®¡åˆ’
        default_step = create_task_step(
            step_id="step_1",
            worker="General",
            description="å¤„ç†ç”¨æˆ·è¯·æ±‚",
        )
        return {
            "task_plan": [default_step],
            "current_step_index": 0,
        }
    
    async def _route_decision(state: SupervisorState, registry) -> Dict[str, Any]:
        """
        è·¯ç”±å†³ç­–é˜¶æ®µ
        
        æ ¹æ®ä»»åŠ¡è®¡åˆ’å’Œå½“å‰è¿›åº¦ï¼Œå†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œã€‚
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. å¿«é€Ÿè·¯å¾„ï¼šå•æ­¥ä»»åŠ¡å®Œæˆåç›´æ¥ç»“æŸï¼Œä¸è°ƒç”¨ LLM
        2. è¿›åº¦æ£€æŸ¥ï¼šæ‰€æœ‰æ­¥éª¤å®Œæˆåç›´æ¥ç»“æŸ
        3. é¡ºåºæ‰§è¡Œï¼šæŒ‰è®¡åˆ’é¡ºåºæ‰§è¡Œï¼Œå‡å°‘ LLM è°ƒç”¨
        """
        task_plan = state.get("task_plan", [])
        current_step_index = state.get("current_step_index", 0)
        
        # è®¡ç®—å®Œæˆè¿›åº¦
        completed_steps = sum(
            1 for step in task_plan 
            if step.get("status") in [TaskStatus.COMPLETED, TaskStatus.SKIPPED]
        )
        total_steps = len(task_plan)
        
        # ===== å¿«é€Ÿè·¯å¾„ 1ï¼šæ‰€æœ‰æ­¥éª¤éƒ½å·²å®Œæˆ =====
        if completed_steps >= total_steps and total_steps > 0:
            logger.info("ğŸ¯ [Supervisor] æ‰€æœ‰ä»»åŠ¡æ­¥éª¤å·²å®Œæˆï¼Œå†³ç­–: FINISH")
            thinking_step = create_thinking_step(
                step_type="decision",
                content="æ‰€æœ‰ä»»åŠ¡æ­¥éª¤å·²å®Œæˆï¼Œå‡†å¤‡ç»“æŸæµç¨‹",
            )
            return {
                "next": "FINISH",
                "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
            }
        
        # ===== å¿«é€Ÿè·¯å¾„ 2ï¼šå•æ­¥ç®€å•ä»»åŠ¡ï¼ŒWorker å·²å›å¤ï¼Œç›´æ¥ç»“æŸ =====
        # æ£€æŸ¥æ˜¯å¦æœ‰ Worker å·²ç»ç»™å‡ºäº†å›å¤
        messages = state.get("messages", [])
        has_ai_response = any(
            hasattr(msg, 'name') and msg.name in registry.get_names()
            for msg in messages
            if hasattr(msg, 'content') and msg.content
        )
        
        if total_steps == 1 and completed_steps == 0 and has_ai_response:
            # å•æ­¥ä»»åŠ¡ï¼Œä¸”æœ‰ Worker å›å¤ï¼Œç›´æ¥ç»“æŸ
            logger.info("ğŸ¯ [Supervisor] å•æ­¥ä»»åŠ¡å·²æœ‰å›å¤ï¼Œå†³ç­–: FINISH")
            thinking_step = create_thinking_step(
                step_type="decision",
                content="å•æ­¥ä»»åŠ¡å·²å®Œæˆï¼Œå‡†å¤‡ç»“æŸæµç¨‹",
            )
            return {
                "next": "FINISH",
                "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
            }
        
        # ===== å¿«é€Ÿè·¯å¾„ 3ï¼šæŒ‰ä»»åŠ¡è®¡åˆ’é¡ºåºæ‰§è¡Œï¼ˆä¸è°ƒç”¨ LLMï¼‰=====
        worker_names = registry.get_names()
        worker_names_lower = {name.lower(): name for name in worker_names}
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªæœªå®Œæˆçš„æ­¥éª¤
        for i, step in enumerate(task_plan):
            step_status = step.get("status")
            # å¤„ç† status å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æšä¸¾çš„æƒ…å†µ
            if isinstance(step_status, str):
                is_completed = step_status in ["completed", "skipped", "failed"]
            else:
                is_completed = step_status in [TaskStatus.COMPLETED, TaskStatus.SKIPPED, TaskStatus.FAILED]
            
            if not is_completed:
                next_worker = step.get("worker", "General")
                # å¤„ç† LLM å¯èƒ½è¿”å›å¸¦æœ‰ç±»å‹æ ‡è®°çš„ Worker åç§°ï¼Œå¦‚ "Researcher [llm_powered]"
                if "[" in next_worker:
                    next_worker = next_worker.split("[")[0].strip()
                # å°è¯•ç²¾ç¡®åŒ¹é…
                if next_worker in worker_names:
                    logger.info(f"ğŸ¯ [Supervisor] æŒ‰è®¡åˆ’æ‰§è¡Œæ­¥éª¤ {i+1}: {next_worker}")
                    thinking_step = create_thinking_step(
                        step_type="decision",
                        content=f"æŒ‰è®¡åˆ’æ‰§è¡Œ: {step.get('description', 'å¤„ç†ä»»åŠ¡')}",
                    )
                    return {
                        "next": next_worker,
                        "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
                    }
                # å°è¯•ä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
                elif next_worker.lower() in worker_names_lower:
                    actual_worker = worker_names_lower[next_worker.lower()]
                    logger.info(f"ğŸ¯ [Supervisor] æŒ‰è®¡åˆ’æ‰§è¡Œæ­¥éª¤ {i+1}: {actual_worker} (åŸå: {next_worker})")
                    thinking_step = create_thinking_step(
                        step_type="decision",
                        content=f"æŒ‰è®¡åˆ’æ‰§è¡Œ: {step.get('description', 'å¤„ç†ä»»åŠ¡')}",
                    )
                    return {
                        "next": actual_worker,
                        "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
                    }
                else:
                    # Worker åç§°æ— æ•ˆï¼Œä½¿ç”¨ General ä½œä¸ºå¤‡é€‰
                    logger.warning(f"è®¡åˆ’ä¸­çš„ Worker '{next_worker}' ä¸å­˜åœ¨ï¼Œä½¿ç”¨ General ä»£æ›¿")
                    if "General" in worker_names:
                        thinking_step = create_thinking_step(
                            step_type="decision",
                            content=f"æŒ‰è®¡åˆ’æ‰§è¡Œ: {step.get('description', 'å¤„ç†ä»»åŠ¡')}ï¼ˆä½¿ç”¨ General ä»£æ›¿ï¼‰",
                        )
                        return {
                            "next": "General",
                            "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
                        }
        
        # ===== å¦‚æœä¸Šè¿°å¿«é€Ÿè·¯å¾„éƒ½ä¸æ»¡è¶³ï¼Œæ‰è°ƒç”¨ LLM å†³ç­– =====
        # ï¼ˆè¿™ç§æƒ…å†µåº”è¯¥å¾ˆå°‘å‘ç”Ÿï¼Œä¸»è¦ç”¨äºå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ï¼‰
        worker_list = registry.get_formatted_descriptions()
        
        task_plan_str = _format_task_plan(task_plan)
        prompt = _build_routing_prompt(
            worker_list=worker_list,
            worker_names=worker_names,
            task_plan=task_plan_str,
            completed_steps=completed_steps,
            total_steps=total_steps,
        )
        
        try:
            llm = _fixed_llm or _get_llm_from_state(state, temperature=config.temperature)
            routing_chain = prompt | llm.with_structured_output(RouteDecision)
            result = await routing_chain.ainvoke({"messages": state.get("messages", [])})
            
            if isinstance(result, RouteDecision):
                next_action = result.next
                reasoning = result.reasoning
                
                valid_options = ["FINISH"] + worker_names
                if next_action not in valid_options:
                    logger.warning(f"Supervisor è¿”å›äº†æ— æ•ˆçš„è·¯ç”±é€‰é¡¹: {next_action}")
                    
                    # å°è¯•ä» reasoning ä¸­æ™ºèƒ½æå–æ­£ç¡®çš„ Worker åç§°
                    fallback_worker = None
                    reasoning_lower = reasoning.lower() if reasoning else ""
                    for worker_name in worker_names:
                        if worker_name.lower() in reasoning_lower:
                            fallback_worker = worker_name
                            break
                    
                    if fallback_worker:
                        logger.info(f"ä» reasoning ä¸­æ¨æ–­å‡ºç›®æ ‡ Worker: {fallback_worker}")
                        next_action = fallback_worker
                    else:
                        # å¦‚æœè¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡æ­¥éª¤ï¼Œä½¿ç”¨è®¡åˆ’ä¸­çš„ Worker
                        for step in task_plan:
                            if step.get("status") not in [TaskStatus.COMPLETED, TaskStatus.SKIPPED, TaskStatus.FAILED]:
                                planned_worker = step.get("worker", "General")
                                # å¤„ç†å¸¦æœ‰ç±»å‹æ ‡è®°çš„ Worker åç§°
                                if "[" in planned_worker:
                                    planned_worker = planned_worker.split("[")[0].strip()
                                if planned_worker in worker_names:
                                    logger.info(f"ä½¿ç”¨ä»»åŠ¡è®¡åˆ’ä¸­çš„ Worker: {planned_worker}")
                                    next_action = planned_worker
                                    break
                        else:
                            # æœ€ç»ˆå›é€€åˆ° FINISH
                            logger.warning(f"æ— æ³•æ¨æ–­æœ‰æ•ˆçš„ Workerï¼Œä½¿ç”¨ FINISH")
                            next_action = "FINISH"
                
                # å…³é”®æ£€æŸ¥ï¼šå¦‚æœ LLM è¿”å› FINISH ä½†è¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡ï¼Œå¼ºåˆ¶ä½¿ç”¨è®¡åˆ’ä¸­çš„ Worker
                if next_action == "FINISH" and completed_steps < total_steps:
                    logger.warning(f"LLM è¿”å› FINISH ä½†è¿˜æœ‰æœªå®Œæˆä»»åŠ¡ ({completed_steps}/{total_steps})ï¼Œå°è¯•ä½¿ç”¨è®¡åˆ’ä¸­çš„ Worker")
                    for step in task_plan:
                        step_status = step.get("status")
                        if isinstance(step_status, str):
                            is_completed = step_status in ["completed", "skipped", "failed"]
                        else:
                            is_completed = step_status in [TaskStatus.COMPLETED, TaskStatus.SKIPPED, TaskStatus.FAILED]
                        
                        if not is_completed:
                            planned_worker = step.get("worker", "General")
                            # å¤„ç†å¸¦æœ‰ç±»å‹æ ‡è®°çš„ Worker åç§°
                            if "[" in planned_worker:
                                planned_worker = planned_worker.split("[")[0].strip()
                            # å°è¯•æ‰¾åˆ°åŒ¹é…çš„ Worker
                            if planned_worker in worker_names:
                                next_action = planned_worker
                                logger.info(f"å¼ºåˆ¶ä½¿ç”¨è®¡åˆ’ä¸­çš„ Worker: {next_action}")
                                break
                            elif planned_worker.lower() in {n.lower() for n in worker_names}:
                                for wn in worker_names:
                                    if wn.lower() == planned_worker.lower():
                                        next_action = wn
                                        logger.info(f"å¼ºåˆ¶ä½¿ç”¨è®¡åˆ’ä¸­çš„ Worker: {next_action}")
                                        break
                                break
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„ Workerï¼Œä½¿ç”¨ General
                        if "General" in worker_names:
                            next_action = "General"
                            logger.info(f"ä½¿ç”¨ General ä½œä¸ºå¤‡é€‰")
                
                thinking_step = create_thinking_step(
                    step_type="decision",
                    content=reasoning or f"å†³å®šäº¤ç»™ {next_action} å¤„ç†",
                )
                
                logger.info(f"ğŸ¯ [Supervisor] å†³ç­–: {next_action}" + (f" (ç†ç”±: {reasoning})" if reasoning else ""))
                
                if result.should_replan:
                    logger.info("ğŸ”„ [Supervisor] è¯·æ±‚é‡æ–°è§„åˆ’ä»»åŠ¡")
                    return {
                        "task_plan": [],
                        "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
                    }
                
                return {
                    "next": next_action,
                    "thinking_steps": state.get("thinking_steps", []) + [thinking_step],
                }
                
        except Exception as e:
            logger.error(f"è·¯ç”±å†³ç­–æ—¶å‡ºé”™: {e}")
        
        # æœ€ç»ˆé™çº§ï¼šç›´æ¥ç»“æŸ
        return {"next": "FINISH"}
    
    async def supervisor_node(state: SupervisorState) -> Dict[str, Any]:
        """
        Supervisor èŠ‚ç‚¹å‡½æ•°
        
        åŠ¨æ€è·å– Worker åˆ—è¡¨ï¼Œæ”¯æŒè¿è¡Œæ—¶æ³¨å†Œæ–°çš„ Workerã€‚
        """
        try:
            # æ£€æŸ¥è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
            iteration_count = state.get("iteration_count", 0)
            if iteration_count >= config.max_iterations:
                logger.warning(f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {config.max_iterations}ï¼Œå¼ºåˆ¶ç»“æŸ")
                return {
                    "next": "FINISH",
                    "iteration_count": iteration_count,
                    "metadata": {
                        **state.get("metadata", {}),
                        "terminated_reason": "max_iterations_reached"
                    }
                }
            
            logger.info(f"ğŸ¯ [Supervisor] å¼€å§‹å†³ç­–... (è¿­ä»£ {iteration_count + 1})")
            
            # åŠ¨æ€è·å–å½“å‰æ³¨å†Œçš„ Worker
            registry = get_registry()
            if registry.is_empty():
                logger.warning("æ²¡æœ‰æ³¨å†Œä»»ä½• Workerï¼Œé»˜è®¤è¿”å› FINISH")
                return {"next": "FINISH", "iteration_count": iteration_count + 1}
            
            # é˜¶æ®µ 1ï¼šä»»åŠ¡è§„åˆ’ï¼ˆå¦‚æœå¯ç”¨ä¸”è¿˜æ²¡æœ‰è§„åˆ’ï¼‰
            planning_result: Dict[str, Any] = {}
            if config.enable_planning and not state.get("task_plan"):
                planning_result = await _plan_task(state, registry)
                # åˆå¹¶è§„åˆ’ç»“æœå¹¶ç»§ç»­å†³ç­–ï¼ˆæ³¨æ„ï¼šéœ€è¦æŠŠè§„åˆ’ç»“æœå†™å›çŠ¶æ€ï¼Œå¦åˆ™ä¸‹ä¸€è½®ä¼šé‡å¤è§„åˆ’ï¼‰
                state = {**state, **planning_result}
            
            # é˜¶æ®µ 2ï¼šè·¯ç”±å†³ç­–
            routing_result = await _route_decision(state, registry)
            
            return {
                # å…ˆå†™å…¥ planning_resultï¼Œè®© task_plan/current_step_index ç­‰å­—æ®µè¿›å…¥å›¾çŠ¶æ€ï¼›
                # routing_result å…è®¸è¦†ç›–ï¼ˆä¾‹å¦‚ should_replan æ—¶è¿”å› task_plan: []ï¼‰
                **planning_result,
                **routing_result,
                "iteration_count": iteration_count + 1,
            }
            
        except Exception as e:
            logger.error(f"Supervisor å†³ç­–æ—¶å‡ºé”™: {e}")
            return {
                "next": "FINISH",
                "iteration_count": state.get("iteration_count", 0) + 1,
                "metadata": {
                    **state.get("metadata", {}),
                    "error": str(e),
                    "error_type": "supervisor_decision_error"
                }
            }
    
    return supervisor_node
