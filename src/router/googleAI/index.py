import os
from typing import Optional  # æ·»åŠ å¿…è¦çš„ç±»å‹å¯¼å…¥
from fastapi import APIRouter, HTTPException
from dotenv import load_dotenv
from google import genai
from fastapi import HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel


class GeminiAI:
    """Gemini AI å®¢æˆ·ç«¯å°è£…ç±»"""

    # åˆå§‹åŒ– è°·æ­Œ AI
    def __init__(self, api_key: Optional[str] = None):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()

        # è·å–APIå¯†é’¥
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        # å¦‚æœæ²¡æœ‰ key åˆ™é€€å‡º
        if not self.api_key:
            raise ValueError("APIå¯†é’¥æœªæä¾›")

        # åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹
        try:
            self.GeminiAI = genai.Client(api_key=self.api_key).chats.create(
                model="gemini-2.5-flash"
            )
            print("ğŸ¤– Gemini AI å®¢æˆ·ç«¯å·²å¯åŠ¨")
            print("=" * 50)
        except Exception as e:
            print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
            raise ConnectionError(f"æ— æ³•è¿æ¥åˆ°Gemini API: {e}")

    # AIäº¤æµ
    def comminicate(self, text: str, stream: bool = True):
        # text: è¾“å…¥æ–‡æœ¬
        # stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        if not text.strip():
            return ValueError("è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

        try:
            if stream:
                return self.generate_content_response(text=text)
            else:
                return self.generate_content(text=text)
        except Exception as e:
            raise RuntimeError(f"ç”Ÿæˆå†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # æ™®é€šå“åº”  """åŒæ­¥ç”Ÿæˆå†…å®¹"""
    async def generate_content(self, text: str):
        try:
            # ç”Ÿæˆå†…å®¹
            response = self.GeminiAI.send_message(text)
            return response.text
        except Exception as e:
            raise RuntimeError(f"ç”Ÿæˆå†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # æµå¼å“åº”
    async def generate_content_response(self, text: str):

        try:
            response = self.GeminiAI.send_message_stream(text)
            for chunk in response:
                yield chunk.text + "\n"
        except Exception as e:
            print(f"\næµå¼è¾“å‡ºä¸­æ–­: {e}")


# åˆ›å»ºå­è·¯ç”±ï¼ŒæŒ‡å®šå‰ç¼€å’Œæ ‡ç­¾
router = APIRouter(
    prefix="/GoogleAI",  # æ·»åŠ å‰ç¼€
    tags=["GoogleAI"],  # ç”¨äºAPIæ–‡æ¡£åˆ†ç»„
    responses={404: {"description": "Not found"}},  # å…¬å…±å“åº”
)


# åˆ›å»ºAIå®¢æˆ·ç«¯
ai_client = GeminiAI()


# åˆ›å»ºå¼‚æ­¥ç”Ÿæˆå™¨åŒ…è£…å™¨
async def response_generator(ai, text):
    try:
        # ä½¿ç”¨å¼‚æ­¥è¿­ä»£å™¨å¤„ç†æµ
        async for chunk in ai.comminicate(text=text):
            # ç¡®ä¿æ¯ä¸ªæ•°æ®å—éƒ½æ˜¯å­—ç¬¦ä¸²
            print(f"æµå¼è¾“å‡º: {chunk}")
            # import asyncio
            # await asyncio.sleep(2)
            yield str(chunk)
    except Exception as e:
        # æ•è·å¹¶å‘é€æœ€ç»ˆé”™è¯¯
        print(f"æµå¼è¾“å‡ºæ•è·å¹¶å‘é€æœ€ç»ˆé”™è¯¯: {e}")
        yield f"[FATAL ERROR] {str(e)}"


class Params_TYPE(BaseModel):
    text: str


@router.post("/ContentResponse")
async def GoogleAI_Content_Response(params: Params_TYPE):
    # æ£€æŸ¥å‚æ•°ä¸­æ˜¯å¦æœ‰ text å­—æ®µ
    if not params.text.strip():  # éªŒè¯æ–‡æœ¬ä¸ä¸ºç©º
        raise HTTPException(status_code=400, detail="è¯·æ±‚ä¸­ç¼ºå°‘ 'text' å­—æ®µæˆ–å†…å®¹ä¸ºç©º")

    text_content = params.text
    print(f"æ”¶åˆ°æ¶ˆæ¯: {text_content}")

    # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°ä¼ é€’
    return StreamingResponse(
        response_generator(ai=ai_client, text=text_content),
        media_type="text/event-stream",  # æ›´é€‚åˆæµå¼ä¼ è¾“çš„åª’ä½“ç±»å‹
    )


def initGoogleAI(app):
    app.include_router(router)


__all__ = ["initGoogleAI"]
